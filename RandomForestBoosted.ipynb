{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import exposure\n",
    "#from skimage.segmentation import quickshift, slic, watershed\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from osgeo import ogr\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import skimage.feature as feature\n",
    "import math\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#import earthpy as py\n",
    "#from sklearn import preprocessing\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#from xgboost import XGBRFClassifier\n",
    "#import xgboost as xgb\n",
    "\n",
    "# import packages for hyperparameters tuning\n",
    "from hyperopt import hp,fmin,tpe,STATUS_OK,Trials\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, cohen_kappa_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPOSITE\n",
    "## PIXELSIZE\n",
    "pixelsize = 30\n",
    "\n",
    "naip_fn = r'C:\\Users\\10333076966\\Desktop\\Landsat\\RESULTADOS\\1991_L5\\Composite_1991\\COMPOSITE_1991_.tif'\n",
    " \n",
    "driverTiff = gdal.GetDriverByName('GTiff')\n",
    "naip_ds = gdal.Open(naip_fn)\n",
    "nbands = naip_ds.RasterCount\n",
    "band_data = []\n",
    "\n",
    "for i in range(1, nbands+1):\n",
    "    band = naip_ds.GetRasterBand(i).ReadAsArray()\n",
    "    #band_norm = preprocessing.normalize(band)\n",
    "\n",
    "    #out_put = ((band-band.min())/ (band.max()-band.min()))\n",
    "\n",
    "    #scaler = MinMaxScaler()\n",
    "    #bands = scaler.fit_transform(band)\n",
    "    band_data.append(band)\n",
    "    \n",
    "    #band_data.append(out_put)\n",
    "\n",
    "    #band_data.append(band)\n",
    "\n",
    "band_data = np.dstack(band_data)\n",
    "p2, p98 = np.percentile(band_data, (2,98))\n",
    "\n",
    "img = exposure.rescale_intensity(band_data, in_range=(p2, p98))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEGMENTO\n",
    "naip_seg = r'C:\\Users\\10333076966\\Desktop\\Landsat\\RESULTADOS\\1991_L5\\Segmento_1991\\segment_restrito.tif'\n",
    "\n",
    "driverTiff = gdal.GetDriverByName('GTiff')\n",
    "naip_ds = gdal.Open(naip_seg)\n",
    "segments = naip_ds.GetRasterBand(1).ReadAsArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_features(segment_pixels):\n",
    "    features = []\n",
    "    npixels, nbands = segment_pixels.shape\n",
    "    for b in range(nbands):\n",
    "        stats = scipy.stats.describe(segment_pixels[:, b])\n",
    "        band_stats = list(stats.minmax) + list(stats)[2:]\n",
    "        if npixels == 1:\n",
    "            # in this case the variance = nan, change it 0.0\n",
    "            band_stats[3] = 0.0\n",
    "        features += band_stats\n",
    "    return features\n",
    "\n",
    "def segment_sizes(segment_pixels):\n",
    "    features2 = []\n",
    "    area = (segment_pixels.shape[0]*segment_pixels.shape[1])*pixelsize^2\n",
    "    length = ((segment_pixels.shape[0]*segment_pixels.shape[1] * 4)*pixelsize)\n",
    "    compactness = 4*math.pi*area/(length^2)\n",
    "\n",
    "    size_stats = [area,length,compactness]\n",
    "\n",
    "\n",
    "    return size_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\10333076966\\Documents\\Repositorio_GEE\\DisplayGEE\\RandomForestBoosted.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/10333076966/Documents/Repositorio_GEE/DisplayGEE/RandomForestBoosted.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m object3 \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/10333076966/Documents/Repositorio_GEE/DisplayGEE/RandomForestBoosted.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m segment_pixels \u001b[39m=\u001b[39m img[segments \u001b[39m==\u001b[39m \u001b[39mid\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/10333076966/Documents/Repositorio_GEE/DisplayGEE/RandomForestBoosted.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m object_features \u001b[39m=\u001b[39m segment_features(segment_pixels)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/10333076966/Documents/Repositorio_GEE/DisplayGEE/RandomForestBoosted.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m object_features_2 \u001b[39m=\u001b[39m segment_sizes(segment_pixels)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/10333076966/Documents/Repositorio_GEE/DisplayGEE/RandomForestBoosted.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m object3 \u001b[39m=\u001b[39m object_features\u001b[39m+\u001b[39mobject_features_2\n",
      "\u001b[1;32mc:\\Users\\10333076966\\Documents\\Repositorio_GEE\\DisplayGEE\\RandomForestBoosted.ipynb Cell 5\u001b[0m in \u001b[0;36msegment_features\u001b[1;34m(segment_pixels)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/10333076966/Documents/Repositorio_GEE/DisplayGEE/RandomForestBoosted.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m stats \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39mstats\u001b[39m.\u001b[39mdescribe(segment_pixels[:, b])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/10333076966/Documents/Repositorio_GEE/DisplayGEE/RandomForestBoosted.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m band_stats \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(stats\u001b[39m.\u001b[39mminmax) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(stats)[\u001b[39m2\u001b[39m:]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/10333076966/Documents/Repositorio_GEE/DisplayGEE/RandomForestBoosted.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mif\u001b[39;00m npixels \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/10333076966/Documents/Repositorio_GEE/DisplayGEE/RandomForestBoosted.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# in this case the variance = nan, change it 0.0\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/10333076966/Documents/Repositorio_GEE/DisplayGEE/RandomForestBoosted.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     band_stats[\u001b[39m3\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/10333076966/Documents/Repositorio_GEE/DisplayGEE/RandomForestBoosted.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m features \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m band_stats\n",
      "\u001b[1;32mc:\\Users\\10333076966\\Documents\\Repositorio_GEE\\DisplayGEE\\RandomForestBoosted.ipynb Cell 5\u001b[0m in \u001b[0;36msegment_features\u001b[1;34m(segment_pixels)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/10333076966/Documents/Repositorio_GEE/DisplayGEE/RandomForestBoosted.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m stats \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39mstats\u001b[39m.\u001b[39mdescribe(segment_pixels[:, b])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/10333076966/Documents/Repositorio_GEE/DisplayGEE/RandomForestBoosted.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m band_stats \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(stats\u001b[39m.\u001b[39mminmax) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(stats)[\u001b[39m2\u001b[39m:]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/10333076966/Documents/Repositorio_GEE/DisplayGEE/RandomForestBoosted.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mif\u001b[39;00m npixels \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/10333076966/Documents/Repositorio_GEE/DisplayGEE/RandomForestBoosted.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# in this case the variance = nan, change it 0.0\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/10333076966/Documents/Repositorio_GEE/DisplayGEE/RandomForestBoosted.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     band_stats[\u001b[39m3\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/10333076966/Documents/Repositorio_GEE/DisplayGEE/RandomForestBoosted.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m features \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m band_stats\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1366\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:662\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1291\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1253\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:297\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\10333076966\\Anaconda3\\envs\\geo\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2023\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2020\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2022\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001b[1;32m-> 2023\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[0;32m   2025\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2027\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2028\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\10333076966\\Anaconda3\\envs\\geo\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2059\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2056\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2058\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2059\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[0;32m   2061\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[0;32m   2063\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "segment_ids = np.unique(segments)\n",
    "objects = []\n",
    "object_ids = []\n",
    "for id in segment_ids:\n",
    "    object3 = []\n",
    "    segment_pixels = img[segments == id]\n",
    "    object_features = segment_features(segment_pixels)\n",
    "    object_features_2 = segment_sizes(segment_pixels)\n",
    "    object3 = object_features+object_features_2\n",
    "    objects.append(object3)\n",
    "    object_ids.append(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read shapefile to geopandas geodataframe\n",
    "gdf = gpd.read_file(r'C:\\Users\\10333076966\\Desktop\\Landsat\\RESULTADOS\\1991_L5\\Amostras_1991\\AMOSTRAS_1991_.shp')\n",
    "# get names of land cover classes/labels\n",
    "class_names = gdf['label'].unique()\n",
    "# create a unique id (integer) for each land cover class/label\n",
    "class_ids = np.arange(class_names.size) + 1\n",
    "# create a pandas data frame of the labels and ids and save to csv\n",
    "df = pd.DataFrame({'label': class_names, 'id': class_ids})\n",
    "#df.to_csv(r'C:\\Users\\10333076966\\Desktop\\Landsat\\RESULTADOS\\1991_L5\\Amostras_1991\\class_lookup.csv')\n",
    "# add a new column to geodatafame with the id for each class/label\n",
    "gdf['id'] = gdf['label'].map(dict(zip(class_names, class_ids)))\n",
    " \n",
    "# split the truth data into training and test data sets and save each to a new shapefile\n",
    "gdf_train = gdf.sample(frac=0.8)  # 80% of observations assigned to training data (30% to test data)\n",
    "gdf_test = gdf.drop(gdf_train.index)\n",
    "# save training and test data to shapefiles\n",
    "gdf_train.to_file(r'C:\\Users\\10333076966\\Desktop\\Landsat\\RESULTADOS\\1991_L5\\Amostras_1991\\train_data.shp')\n",
    "gdf_test.to_file(r'C:\\Users\\10333076966\\Desktop\\Landsat\\RESULTADOS\\1991_L5\\Amostras_1991\\test_data.shp')\n",
    "print(f'os labels serão: \\n {df}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fn = r'C:\\Users\\10333076966\\Desktop\\Landsat\\RESULTADOS\\1991_L5\\Amostras_1991\\train_data.shp'\n",
    "train_ds = ogr.Open(train_fn)\n",
    "lyr = train_ds.GetLayer()\n",
    "# create a new raster layer in memory\n",
    "driver = gdal.GetDriverByName('MEM')\n",
    "target_ds = driver.Create('', naip_ds.RasterXSize, naip_ds.RasterYSize, 1, gdal.GDT_UInt16)\n",
    "target_ds.SetGeoTransform(naip_ds.GetGeoTransform())\n",
    "target_ds.SetProjection(naip_ds.GetProjection())\n",
    "# rasterize the training points\n",
    "options = ['ATTRIBUTE=id']\n",
    "gdal.RasterizeLayer(target_ds, [1], lyr, options=options)\n",
    "# retrieve the rasterized data and print basic stats\n",
    "data = target_ds.GetRasterBand(1).ReadAsArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rasterized observation (truth, training and test) data\n",
    "ground_truth = target_ds.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "# get unique values (0 is the background, or no data, value so it is not included) for each land cover type\n",
    "\n",
    "classes = np.unique(ground_truth)[1:]\n",
    "\n",
    "# for each class (land cover type) record the associated segment IDs\n",
    "segments_per_class = {}\n",
    "for klass in classes:\n",
    "    segments_of_class = segments[ground_truth == klass]\n",
    "    segments_per_class[klass] = set(segments_of_class)\n",
    " \n",
    "# make sure no segment ID represents more than one class\n",
    "# intersection = set()\n",
    "# accum = set()\n",
    "# for class_segments in segments_per_class.values():\n",
    "#     intersection |= accum.intersection(class_segments)\n",
    "#     accum |= class_segments\n",
    "# assert len(intersection) == 0, \"Segment(s) represent multiple classes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = np.copy(segments)\n",
    "threshold = train_img.max() + 1  # make the threshold value greater than any land cover class value\n",
    "\n",
    "# all pixels in training segments assigned value greater than threshold\n",
    "for klass in classes:\n",
    "    class_label = threshold + klass\n",
    "    for segment_id in segments_per_class[klass]:\n",
    "        train_img[train_img == segment_id] = class_label\n",
    " \n",
    "# training segments receive land cover class value, all other segments 0\n",
    "train_img[train_img <= threshold] = 0\n",
    "train_img[train_img > threshold] -= threshold\n",
    "\n",
    "\n",
    "# create objects and labels for training data\n",
    "training_objects = []\n",
    "training_labels = []\n",
    "for klass in classes:\n",
    "    class_train_object = [v for i, v in enumerate(objects) if segment_ids[i] in segments_per_class[klass]]\n",
    "    training_labels += [klass] * len(class_train_object)\n",
    "    training_objects += class_train_object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing data\n",
    "\n",
    "test_fn = r'C:\\Users\\10333076966\\Desktop\\Landsat\\RESULTADOS\\1991_L5\\Amostras_1991\\test_data.shp'\n",
    "test_ds = ogr.Open(test_fn)\n",
    "lyr = test_ds.GetLayer()\n",
    "# create a new raster layer in memory\n",
    "driver = gdal.GetDriverByName('MEM')\n",
    "target_test = driver.Create('', naip_ds.RasterXSize, naip_ds.RasterYSize, 1, gdal.GDT_UInt16)\n",
    "target_test.SetGeoTransform(naip_ds.GetGeoTransform())\n",
    "target_test.SetProjection(naip_ds.GetProjection())\n",
    "# rasterize the training points\n",
    "options = ['ATTRIBUTE=id']\n",
    "gdal.RasterizeLayer(target_test, [1], lyr, options=options)\n",
    "# retrieve the rasterized data and print basic stats\n",
    "\n",
    "\n",
    "# rasterized observation (truth, training and test) data\n",
    "ground_truth_test = target_test.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "# get unique values (0 is the background, or no data, value so it is not included) for each land cover type\n",
    "classes_test = np.unique(ground_truth_test)[1:]\n",
    "\n",
    "# for each class (land cover type) record the associated segment IDs\n",
    "segments_per_class_test = {}\n",
    "for klass_test in classes_test:\n",
    "    segments_of_class_test = segments[ground_truth_test == klass_test]\n",
    "    segments_per_class_test[klass_test] = set(segments_of_class_test)\n",
    " \n",
    "\n",
    "test_image = np.copy(segments)\n",
    "threshold = test_image.max() + 1  # make the threshold value greater than any land cover class value\n",
    "\n",
    "# all pixels in training segments assigned value greater than threshold\n",
    "for klass_test in classes_test:\n",
    "    class_label = threshold + klass_test\n",
    "    for segment_id in segments_per_class_test[klass_test]:\n",
    "        test_image[test_image == segment_id] = class_label\n",
    " \n",
    "# training segments receive land cover class value, all other segments 0\n",
    "test_image[test_image <= threshold] = 0\n",
    "test_image[test_image > threshold] -= threshold\n",
    "\n",
    "\n",
    "# create objects and labels for TESTING data\n",
    "testing_objects = []\n",
    "testing_labels = []\n",
    "for klass_test in classes:\n",
    "    class_test_object = [v for i, v in enumerate(objects) if segment_ids[i] in segments_per_class_test[klass_test]]\n",
    "    testing_labels += [klass_test] * len(class_test_object)\n",
    "    testing_objects += class_test_object\n",
    " \n",
    "\n",
    "testing_labels = np.asarray(testing_labels, dtype=np.int32)\n",
    "training_labels = np.asarray(training_labels, dtype=np.int32)\n",
    "\n",
    "\n",
    "training_labels[training_labels == max(training_labels)] = 0\n",
    "testing_labels[testing_labels == max(testing_labels)] = 0\n",
    "\n",
    "\n",
    "# for i in range(len(training_labels)):\n",
    "#     if training_labels[i] == max(training_labels):\n",
    "#         training_labels[i] = 0\n",
    "\n",
    "\n",
    "# for i in range(len(testing_labels)):\n",
    "#     if testing_labels[i] == max(testing_labels):\n",
    "#         testing_labels[i] = 0\n",
    "\n",
    "\n",
    "print(f'o maximo de treino labels é: {np.max(training_labels)}' )\n",
    "print(f'o minimo de treino labels é: {np.min(training_labels)}' )\n",
    "\n",
    "\n",
    "print(f'o maximo de teste labels é: {np.max(testing_labels)}' )\n",
    "print(f'o minimo de teste labels é: {np.min(testing_labels)}' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "# y_pred = classifier.predict(testing_objects)\n",
    "# cm = confusion_matrix(testing_labels, y_pred)\n",
    "# print(cm)\n",
    "# accuracy_score(testing_labels,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracies = cross_val_score(estimator=classifier,X=testing_objects,y=testing_labels,cv=10)\n",
    "# print(\"Accuracy: {:.2f}%\".format(accuracies.mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space = {'criterion' : hp.choice('criterion', ['entropy','gini']),\n",
    "#          'max_depth' : hp.quniform('max_depth',10,1200,10),\n",
    "#          'max_features' : hp.choice('max_features',['auto','sqrt','log2',None]),\n",
    "#          'min_samples_leaf' : hp.uniform('min_samples_leaf',0,0.5),\n",
    "#          'min_samples_split' : hp.uniform('min_samples_split',0,1),\n",
    "#          'n_estimators': hp.choice('n_estimators',[10,50,350,550,750,1200,1300,1500])\n",
    "# }\n",
    "\n",
    "# def objective(space):\n",
    "#     model = RandomForestClassifier( criterion = space['criterion'],\n",
    "#                                     max_depth = int(space['max_depth']),\n",
    "#                                     max_features = space['max_features'],\n",
    "#                                     min_samples_leaf = space['min_samples_leaf'],\n",
    "#                                     min_samples_split = space['min_samples_split'],\n",
    "#                                     n_estimators = space['n_estimators']\n",
    "#     )\n",
    "    \n",
    "#     accuracy = cross_val_score(model, training_objects,training_labels,cv=10).mean()\n",
    "#     return {'loss' : -accuracy , 'status' : STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trials = Trials()\n",
    "# best = fmin(fn = objective,\n",
    "#             space=space,\n",
    "#             algo= tpe.suggest,\n",
    "#             max_evals=80,\n",
    "#             trials=trials\n",
    "#            )\n",
    "# best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = 'entropy'\n",
    "best = int(1000)\n",
    "max_features = 'log2'\n",
    "min_samples_leaf = 0.028945223804323825\n",
    "min_samples_split = 0.06565805024545149\n",
    "n_estimators = 1300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crit = {0: 'entropy', 1: 'gini'}\n",
    "# feat = {0: 'auto', 1: 'sqrt', 2: 'log2', 3: None}\n",
    "# est = {0: 10, 1: 50, 2: 350, 3: 550, 4: 750, 5: 1200, 6: 1300, 7: 1500}\n",
    "\n",
    "# print(crit[best['criterion']])\n",
    "# print(feat[best['max_features']])\n",
    "# print(est[best['n_estimators']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedforest = RandomForestClassifier(criterion = crit[best['criterion']], max_depth = int(best['max_depth']), \n",
    "                                       max_features = feat[best['max_features']], \n",
    "                                       min_samples_leaf = best['min_samples_leaf'], \n",
    "                                       min_samples_split = best['min_samples_split'], \n",
    "                                       n_estimators = est[best['n_estimators']]).fit(training_objects,training_labels)\n",
    "\n",
    "\n",
    "\n",
    "                                       \n",
    "predictionforest = trainedforest.predict(testing_objects)\n",
    "predicted = trainedforest.predict(objects)\n",
    "\n",
    "\n",
    "\n",
    "print(confusion_matrix(testing_labels,predictionforest))\n",
    "print(f'A acurácia global é de : {round(accuracy_score(testing_labels,predictionforest),4)}')\n",
    "print(classification_report(testing_labels,predictionforest))\n",
    "acc5 = accuracy_score(testing_labels,predictionforest)\n",
    "kappa = cohen_kappa_score(testing_labels, predictionforest)\n",
    "print(f'O kappa é de : {round(kappa,4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_jobs=-1)  # setup random forest classifier\n",
    "classifier.fit(training_objects, training_labels)  # fit rf classifier\n",
    "predicted = classifier.predict(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace segments with the predicted classes\n",
    "clf = np.copy(segments)\n",
    "\n",
    "mask = np.isin(clf, segment_ids)\n",
    "clf[mask] = predicted[np.searchsorted(segment_ids, clf[mask])]\n",
    "\n",
    "mask = np.sum(img, axis=2)  # this section masks no data values\n",
    "mask[mask > 0.0] = 1.0\n",
    "mask[mask == 0.0] = 1.0\n",
    "mask[mask == 0.0] = -1.0\n",
    "clf = np.multiply(clf, mask)\n",
    "clf[clf < 0] = -9999.0\n",
    "\n",
    "# Save the result to raster\n",
    "clfds = driverTiff.Create(r'C:\\Users\\10333076966\\Documents\\GEOPROCESSAMENTO\\Temp\\SUBSET\\CLASSIFIED.tif', naip_ds.RasterXSize, naip_ds.RasterYSize,\n",
    "                          1, gdal.GDT_Float32)\n",
    "clfds.SetGeoTransform(naip_ds.GetGeoTransform())\n",
    "clfds.SetProjection(naip_ds.GetProjection())\n",
    "clfds.GetRasterBand(1).SetNoDataValue(-9999.0)\n",
    "clfds.GetRasterBand(1).WriteArray(clf)\n",
    "clfds = None\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFECV (number of features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# Init, fit\n",
    "rfecv = RFECV(\n",
    "    estimator=trainedforest,\n",
    "    min_features_to_select=3,\n",
    "    step=1,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"r2\",\n",
    "    cv=5,\n",
    ")\n",
    "\n",
    "_ = rfecv.fit(img[ground_truth > 0], ground_truth[ground_truth > 0])\n",
    "\n",
    "print(f\"o número de features a serem selecionadas é de: {rfe.support_.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFE (Recursive feature selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RFE \n",
    "rfe = RFE(estimator=trainedforest, n_features_to_select=6, step = 1)\n",
    "\n",
    "\n",
    "rfe.fit(img[ground_truth > 0], ground_truth[ground_truth > 0])\n",
    "\n",
    "for i in range(img.shape[2]):\n",
    "\tprint('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    " \n",
    "# read original image to get info for raster dimensions\n",
    "naip_fn = r'C:\\Users\\10333076966\\Documents\\Temp\\TestePCA\\CLASSIFICADOR\\BSI_NDVI_B1B2B3B4_NDWI_subset.tif'\n",
    "driverTiff = gdal.GetDriverByName('GTiff')\n",
    "naip_ds = gdal.Open(naip_fn)\n",
    " \n",
    "# rasterize test data for pixel-to-pixel comparison\n",
    "test_fn = r'C:\\Users\\10333076966\\Documents\\Temp\\IMAGENS_PARA_TESTE\\Amostras\\test_data.shp'\n",
    "test_ds = ogr.Open(test_fn)\n",
    "lyr = test_ds.GetLayer()\n",
    "driver = gdal.GetDriverByName('MEM')\n",
    "target_ds = driver.Create('', naip_ds.RasterXSize, naip_ds.RasterYSize, 1, gdal.GDT_UInt16)\n",
    "target_ds.SetGeoTransform(naip_ds.GetGeoTransform())\n",
    "target_ds.SetProjection(naip_ds.GetProjection())\n",
    "options = ['ATTRIBUTE=id']\n",
    "gdal.RasterizeLayer(target_ds, [1], lyr, options=options)\n",
    " \n",
    "truth = target_ds.GetRasterBand(1).ReadAsArray()  # truth/test data array\n",
    " \n",
    "pred_ds = gdal.Open(r'C:\\Users\\10333076966\\Documents\\Temp\\TestePCA\\classified_result_xgbost.tif')  \n",
    "pred = pred_ds.GetRasterBand(1).ReadAsArray()  # predicted data array\n",
    "idx = np.nonzero(truth) # get indices where truth/test has data values\n",
    "cm = metrics.confusion_matrix(truth[idx], pred[idx])  # create a confusion matrix at the truth/test locations\n",
    "scores = metrics.accuracy_score(truth[idx], pred[idx])\n",
    "\n",
    "# pixel accuracy\n",
    "print(cm)\n",
    "\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#level 2 scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('geo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "539ff20f4ee1d590eff0393f3a020850b595bcb7a8e76cc93c9854686ef3e2cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
